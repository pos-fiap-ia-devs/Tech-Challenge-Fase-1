{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü¶ü Tech Challenge - Sistema de Diagn√≥stico de Dengue com ML\n",
    "\n",
    "## Objetivo\n",
    "Desenvolver um modelo de Machine Learning capaz de classificar casos suspeitos de dengue em **Confirmado** ou **Descartado**, utilizando dados cl√≠nicos e epidemiol√≥gicos do SINAN (2022)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importa√ß√£o de Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import os\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, recall_score, f1_score, roc_auc_score, precision_score, roc_curve\n",
    "\n",
    "# Modelos\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Desbalanceamento\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# Interpreta√ß√£o\n",
    "import shap\n",
    "\n",
    "# Configura√ß√µes\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fase 1: Explora√ß√£o de Dados\n",
    "- Carregamento do dataset\n",
    "- An√°lise inicial (Missing values, Distribui√ß√£o de classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar Dataset\n",
    "filename = 'DENGBR22.csv'\n",
    "\n",
    "if os.path.exists(filename):\n",
    "    df = pd.read_csv(filename, low_memory=False)\n",
    "    print(f\"Dataset carregado com sucesso! Dimens√µes: {df.shape}\")\n",
    "else:\n",
    "    print(f\"‚ùå Erro: Arquivo '{filename}' n√£o encontrado.\")\n",
    "    print(f\"Diret√≥rio atual de trabalho: {os.getcwd()}\")\n",
    "    print(\"Arquivos no diret√≥rio atual:\", os.listdir())\n",
    "    # Levantar erro para parar a execu√ß√£o e n√£o causar NameError depois\n",
    "    raise FileNotFoundError(f\"Arquivo {filename} n√£o encontrado no diret√≥rio atual.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar primeiras linhas\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribui√ß√£o da vari√°vel alvo original\n",
    "print(\"Distribui√ß√£o original de CLASSI_FIN:\")\n",
    "print(df['CLASSI_FIN'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fase 2: Pr√©-processamento e Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Filtrar Classes Relevantes\n",
    "# Manter apenas: 1 (Confirmado - Cl√°ssico), 2 (Descartado), 10 (Dengue), 11 (Dengue com sinais de alarme), 12 (Dengue grave)\n",
    "# Obs: O dicion√°rio pode variar. Assumindo mapeamento padr√£o do SINAN para 2022:\n",
    "# Vamos focar em: 10, 11, 12 como POSITIVO e 5 como DESCARTADO (verificar dicion√°rio exato)\n",
    "# Baseado no planejamento anterior e prompt: \n",
    "# \"Classifica√ß√£o Final: 1 (Confirmado) vs 2 (Descartado)\" -> Vamos filtrar estes primeiro.\n",
    "\n",
    "# *Ajuste conforme dicion√°rio espec√≠fico do ano se necess√°rio*\n",
    "# Para este exerc√≠cio, seguiremos a instru√ß√£o: \"1 e 2\"\n",
    "\n",
    "df_clean = df[df['CLASSI_FIN'].isin([1, 2])].copy()\n",
    "print(f\"Registros ap√≥s filtro de classe (1 ou 2): {df_clean.shape}\")\n",
    "\n",
    "# Mapear Target: 1 -> 1 (Positivo), 2 -> 0 (Negativo)\n",
    "df_clean['target'] = df_clean['CLASSI_FIN'].map({1: 1, 2: 0})\n",
    "print(\"Distribui√ß√£o do Target:\")\n",
    "print(df_clean['target'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Tratamento de Idade (NU_IDADE_N)\n",
    "def tratar_idade(valor):\n",
    "    valor_str = str(valor).zfill(4)\n",
    "    unidade = int(valor_str[0])\n",
    "    qtd = int(valor_str[1:])\n",
    "    \n",
    "    if unidade == 4: # Anos\n",
    "        return qtd\n",
    "    elif unidade == 3: # Meses\n",
    "        return qtd / 12\n",
    "    elif unidade == 2: # Dias\n",
    "        return qtd / 365\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "df_clean['idade_anos'] = df_clean['NU_IDADE_N'].apply(tratar_idade)\n",
    "df_clean = df_clean.dropna(subset=['idade_anos']) # Remover idades inv√°lidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Sele√ß√£o de Features\n",
    "\n",
    "features_sintomas = [\n",
    "    'FEBRE', 'MIALGIA', 'CEFALEIA', 'EXANTEMA', 'VOMITO', 'NAUSEA', \n",
    "    'DOR_COSTAS', 'CONJUNTVIT', 'ARTRITE', 'ARTRALGIA', 'PETEQUIA_N', \n",
    "    'LEUCOPENIA', 'LACO', 'DOR_RETRO'\n",
    "]\n",
    "\n",
    "features_comorbidades = [\n",
    "    'DIABETES', 'HEMATOLOG', 'HEPATOPAT', 'RENAL', 'HIPERTENSA', \n",
    "    'ACIDO_PEPT', 'AUTO_IMUNE'\n",
    "]\n",
    "\n",
    "features_demograficas = ['CS_SEXO', 'CS_GESTANT', 'CS_RACA', 'CS_ESCOL_N']\n",
    "\n",
    "# Converter bin√°rios (1=Sim, 2=N√£o) -> (1, 0)\n",
    "for col in features_sintomas + features_comorbidades:\n",
    "    # Preencher NaN com 2 (N√£o) antes de converter, assumindo aus√™ncia de registro como negativo\n",
    "    # Ou usar estrat√©gia mais conservadora. Vamos preencher com 2.\n",
    "    df_clean[col] = df_clean[col].fillna(2)\n",
    "    df_clean[col] = df_clean[col].apply(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "# Feature Engineering: Contagens\n",
    "df_clean['qtd_sintomas'] = df_clean[features_sintomas].sum(axis=1)\n",
    "df_clean['qtd_comorbidades'] = df_clean[features_comorbidades].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamento de Dados Temporais\n",
    "df_clean['DT_NOTIFIC'] = pd.to_datetime(df_clean['DT_NOTIFIC'], errors='coerce')\n",
    "df_clean['mes_notificacao'] = df_clean['DT_NOTIFIC'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar X e y\n",
    "cols_to_use = features_sintomas + features_comorbidades + ['idade_anos', 'qtd_sintomas', 'qtd_comorbidades', 'mes_notificacao']\n",
    "\n",
    "X = df_clean[cols_to_use]\n",
    "y = df_clean['target']\n",
    "\n",
    "# Tratamento de Missings (Imputa√ß√£o simples para num√©ricas/restantes)\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "print(\"Shape final de X:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correla√ß√£o\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(df_clean[cols_to_use + ['target']].corr(), annot=False, cmap='coolwarm')\n",
    "plt.title(\"Matriz de Correla√ß√£o\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fase 3: Modelagem e Avalia√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Treino/Teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, stratify=y, random_state=42)\n",
    "\n",
    "print(f\"Treino: {X_train.shape}, Teste: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipelines de Modelos\n",
    "# Usaremos scaler se necess√°rio (p/ Regress√£o Log√≠stica)\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced'))\n",
    "    ]),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced', n_jobs=-1),\n",
    "    'XGBoost': XGBClassifier(random_state=42, eval_metric='logloss', scale_pos_weight=y_train.value_counts()[0]/y_train.value_counts()[1])\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Treinando {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predi√ß√µes\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # M√©tricas\n",
    "    tp = recall_score(y_test, y_pred)\n",
    "    fp = 1 - precision_score(y_test, y_pred, zero_division=0)\n",
    "    \n",
    "    results[name] = {\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred, zero_division=0),\n",
    "        'F1-Score': f1_score(y_test, y_pred),\n",
    "        'AUC-ROC': roc_auc_score(y_test, y_proba),\n",
    "        'Model': model\n",
    "    }\n",
    "    \n",
    "    print(f\"--- {name} ---\")\n",
    "    print(f\"Recall: {results[name]['Recall']:.4f}\")\n",
    "    print(f\"AUC-ROC: {results[name]['AUC-ROC']:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabela Comparativa\n",
    "df_res = pd.DataFrame(results).T.drop(columns=['Model'])\n",
    "df_res[['Recall', 'Precision', 'F1-Score', 'AUC-ROC']].style.background_gradient(cmap='Greens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fase 5: Interpreta√ß√£o (SHAP e Import√¢ncia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance (Random Forest)\n",
    "rf_model = results['Random Forest']['Model']\n",
    "importances = pd.Series(rf_model.feature_importances_, index=X.columns)\n",
    "importances.sort_values(ascending=False).head(15).plot(kind='barh', title='Top 15 Feature Importances (RF)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP Values (XGBoost) - Implementa√ß√£o Robusta\n",
    "import shap\n",
    "\n",
    "# Inicializar JS (necess√°rio para alguns plots interativos no notebook)\n",
    "shap.initjs()\n",
    "\n",
    "try:\n",
    "    xgb_model = results['XGBoost']['Model']\n",
    "    \n",
    "    # Usar uma amostra do teste para agilizar (SHAP pode ser lento)\n",
    "    X_sample = X_test.iloc[:500]\n",
    "    \n",
    "    print(\"Calculando SHAP values...\")\n",
    "    \n",
    "    # Tentar usar o TreeExplainer (espec√≠fico para √°rvores)\n",
    "    explainer = shap.TreeExplainer(xgb_model)\n",
    "    \n",
    "    # Calcular shape values\n",
    "    # check_additivity=False pode ser necess√°rio em alguns casos de instabilidade num√©rica\n",
    "    shap_values = explainer.shap_values(X_sample, check_additivity=False)\n",
    "    \n",
    "    # Tratamento para outputs diferentes (algumas vers√µes retornam lista para classifica√ß√£o)\n",
    "    if isinstance(shap_values, list):\n",
    "        print(\"SHAP retornou lista (provavelmente classes separadas). Usando classe positiva.\")\n",
    "        # Para bin√°rio, o √≠ndice 1 geralmente √© a classe positiva\n",
    "        shap_values_to_plot = shap_values[1]\n",
    "    else:\n",
    "        shap_values_to_plot = shap_values\n",
    "        \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    shap.summary_plot(shap_values_to_plot, X_sample, show=True)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao gerar an√°lise SHAP: {e}\")\n",
    "    print(\"Dica: Verifique se o pacote 'shap' est√° instalado corretamente e se as vers√µes s√£o compat√≠veis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discuss√£o dos Resultados\n",
    "\n",
    "- **Recall:** Priorizamos esta m√©trica pois falsos negativos s√£o perigosos no contexto de dengue.\n",
    "- **Vari√°veis Importantes:** A an√°lise SHAP mostra quais sintomas e comorbidades mais impactam o diagn√≥stico."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
